{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Theorem\n",
    "- 저번에 다뤘던 joint probability와 conditional probaility에 이어서 이번에는 Bayes theorem에 대해서 다뤄보겠습니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bayesian 관점에서 확률! 기억하시나요?\n",
    "- 확률이란 '이미 일어난 사건이 특정 사건에 속할 가능성,신뢰도'를 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  What is Bayes Theorem?\n",
    "- 사건 B가 발생함으로써(사건 B가 진실이라는 것을 알게 됨으로써, P(B)=1이라는 것을 알게 됨으로써) 사건 A의 확률이 어떻게 변화하는지를 표현한 정리입니다!! \n",
    "\n",
    "- P(A|B) = P(B|A)P(A) / P(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 수식에 대한 증명:\n",
    "- P(A|B)=P(A,B)/P(B) > P(A,B)=P(A|B)P(B)\n",
    "- P(B|A)=P(A,B)/P(A) > P(A,B)=P(B|A)P(A)\n",
    "- `P(A,B)=P(A|B)P(B) = P(B|A)P(A)`\n",
    "- `P(A|B)=P(B|A)P(A)/P(B)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- P(A) : 사전확률(prior)\n",
    "- P(A|B) : 사후확률(posterior)\n",
    "- P(B|A) : likelihood \n",
    "- P(B) : normalizing constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 베이즈 정리의 확장 1\n",
    "- 전체 확률의 법칙을 기억하시나요? \n",
    "    - 사건 A_i가 1)서로 교집합이 없고 2) 이들의 합집합이 전체 집합(오메가)를 구성하면,\n",
    "- P(A_i|B) = P(B|A_1)P(A_i) / P(B) = \n",
    "- P(B|A_1)P(A_i) / `sigma_i(P(A_i,B)` =\n",
    "- P(B|A_1)P(A_i)/`sigma(P(B|A_i)P(A_i))`\n",
    "- ` ` 이 전체 확률 법칙을 이용한 부분입니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pgmpy(Probabilistic Graphical Models in Python)을 사용한 베이즈 정리\n",
    "- `pgmpy` 패키지에서는 conditional_probability를 정의할 수 있는 `TabularCPD` 클래스와 베이즈 정리를 적용할 수 있는 `BayesianModel` 클래스를 제공합니다.\n",
    "\n",
    "- TabularCPD(variable, variable_card, value, evidence, evidence_card)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "검사 시약 문제에 Bayes Theorem을 적용시켜서 확률을 계산해보겠습니다!\n",
    "- 병에 걸린 환자에게 양성 반응 검사를 했을 때, 그 확률이 99%였다 P(S|D) = 0.99\n",
    "- 이 병은 전체 인구 중 걸린 사람이 0.2%인 희귀병이다. P(D) = 0.002\n",
    "- 이 병에 걸리지 않은 사람에게 시약 검사를 했을 때, 양성 반응(False Positive)가 나타난 확률이 5%이다. P(S|D_complement) = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.factors.discrete import TabularCPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════╤═══════╕\n",
      "│ D_0 │ 0.998 │\n",
      "├─────┼───────┤\n",
      "│ D_1 │ 0.002 │\n",
      "╘═════╧═══════╛\n"
     ]
    }
   ],
   "source": [
    "cpd_D = TabularCPD('D',2,[[1 - 0.002, 0.002]])\n",
    "print(cpd_D)\n",
    "# 여기서 D_0는 희귀병에 걸리지 않은 사람의 확률, D_1은 희귀병에 걸릴 인구의 확률입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 여기서 잠깐! TabularCPD에 대해서 짚고 넘어가 봅시다!!\n",
    "- Defines the conditional probability distribution table (cpd table)\n",
    "- 조건부 확률 분포 테이블을 만들어주는 메소드입니다. \n",
    "- variable: int, string (any hashable python object)\n",
    "    - The variable whose CPD is defined.\n",
    "    - 확률 변수의 이름 문자열\n",
    "\n",
    "- variable_card: integer\n",
    "    - cardinality of variable\n",
    "    - 확률 변수가 가질 수 있는 경우의 수\n",
    "\n",
    "- values: 2d array, 2d list or 2d tuple\n",
    "    - values of the cpd table\n",
    "    - 조건부 확률 배열, 하나의 열이 하나의 조건을 의미하기 때문에 하나의 열의 확률 합은 1이여야 합니다. \n",
    "- evidence: array-like\n",
    "    - evidences(if any) w.r.t. which cpd is defined\n",
    "    - 조건이 되는 확률 변수의 이름 문자열 리스트\n",
    "    \n",
    "- evidence_card: integer, array-like\n",
    "    - cardinality of evidences (if any)\n",
    "    - 조건이 되는 확률 변수가 가질 수 있는 경우의 수의 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════╤══════╤══════╕\n",
      "│ D   │ D_0  │ D_1  │\n",
      "├─────┼──────┼──────┤\n",
      "│ S_0 │ 0.95 │ 0.01 │\n",
      "├─────┼──────┼──────┤\n",
      "│ S_1 │ 0.05 │ 0.99 │\n",
      "╘═════╧══════╧══════╛\n"
     ]
    }
   ],
   "source": [
    "cpd_SD = TabularCPD('S',2,np.array([[0.95,0.01],[0.05,0.99]]),\\\n",
    "evidence=['D'],evidence_card=[2])\n",
    "print(cpd_SD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 conditional_probabiltiy distribution table에 대해서 이해하셨나요?!(저만 힘들었나요..?!!) 굳건하게 설명들어가겠습니다!!\n",
    "\n",
    "-  조건이 되는 확률 변수에 D가 들어갔습니다! 즉, 희귀병 환자의 인구 비율이 조건이 된 것입니다!\n",
    "- 따라서 D_1(환자)를 조건으로 하는 S_1(양성반응) 확률은 위에서 제시해준대로 0.99이고 이의 나머지 확률은 자연히 0.01이 됩니다!\n",
    "- 다른 조건에 따라서, False Positive한 확률값 조건 D_0(병에 걸리지 않은 사람)이 S_1일 확률(양성 반응)이 0.05였고 자연히 0.95가 같은 열의 다른 index에 들어가게 됩니다!\n",
    "- 여기서 중요한 점은, 조건이(evidence로 주어진 값)이 D(희귀병 환자의 확률)이였고 이에 따라서, D가 위치한 column의 합계가 각각 1이 되어야 합니다!!!!! `cpd_SD[D_0] = cpd_SD[1] = 1` 당연한 이야기이지만 나름 개념적으로 중요한 이야기입니다~!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 조건부 확률과 조건이 되는 확률을 결합하기 위해서는 `BayesianModel` 클래스 객체를 만들고 `add_cpds` 메서드로 위에서 구현한 조건부 확률을 추가해 줍니다. `check_model` 메서드로 모형이 완전한지 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.models import BayesianModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BayesianModel([('D','S')])\n",
    "model.add_cpds(cpd_D,cpd_SD)\n",
    "model.check_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`BayesianModel` 클래스는 변수 제거법(VariableElimination)을 사용한 추정을 제공합니다. 자세한 설명은 아직 저도 안 배웠으니 나중으로 미루도록 하겠습니다...ㅎ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════╤══════════╕\n",
      "│ D   │   phi(D) │\n",
      "╞═════╪══════════╡\n",
      "│ D_0 │   0.9618 │\n",
      "├─────┼──────────┤\n",
      "│ D_1 │   0.0382 │\n",
      "╘═════╧══════════╛\n"
     ]
    }
   ],
   "source": [
    "from pgmpy.inference import VariableElimination\n",
    "\n",
    "infer = VariableElimination(model)\n",
    "posterior = infer.query(['D'], evidence={'S': 1})\n",
    "print(posterior['D'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 베이즈 정리의 확장 2\n",
    "- 베이즈 정리는 사건 A의 확률이 사건 B에 의해 업데이트된 확률을 계산합니다.\n",
    "- 만약! 이 상태에서 추가적인 사건 C가 발생했다면 -> P(A|B,C)=?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- P(A|B,C) = P(C|A,B)P(A|B) / P(C|B)\n",
    "    - proof:\n",
    "        - P(A,B,C)/P(B,C) = P(C|A,B)P(A,B) / P(C|B)P(B) = \n",
    "        - P(C|A,B)P(A|B)P(B) / P(C|B)P(B) = \n",
    "        - P(C|A,B)P(A|B) / P(C|B)\n",
    "- 마크다운의 한계가 보이네요...빨리 LaTex를 연습하겠습니다..아직은 쓰면서 익혀주세요!!ㅠㅠ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 베이즈 정리의 확장2를 사용해서 다음과 같은 등식도 성립할 수 있습니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- P(A|B,C) = P(B|A,C)P(A|C) / P(B|C)\n",
    "- 등식을 무조건 외우기 보다 `패턴`을 파악해봅시다!! 무엇이 보이시나요??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 기존의 Conditional_Probability : P(A|B) = P(B|A)P(A) / P(B)\n",
    "- 추가된 condition 사건 B(bayes expansion 2)과 비교해보게 되면!! \n",
    "    - `likelihood, prior, normalizing constant` 세 가지 components에 전부 추가된 condition event가 들어있음을 확인할 수 있습니다!! (이렇게 생각하면 참 쉽죠..??)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 좀 더 나아가봅시다!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P(A,B|C,D) = P(B,C|A,D)P(A,B|D) / P(B,C|D)\n",
    "- posterior = P(A,B|C,D)\n",
    "- prior = P(A,B|D)\n",
    "- likelihood = P(B,C|A,D)\n",
    "- 여기서도 패턴을 파악해봅시다!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 추가된 것은?? 조건으로 들어간 사건 C!!!\n",
    "- 이에 따라 likelihood가 어떻게 변했는지에 집중해보자!!\n",
    "    - 참고로 normalizing constant는 후에 상대비교에 따라 중요도가 떨어지기 때문에 베이즈 정리 자체에서 정규화 상수에 대한 중요도는 점점 떨어지게 됩니다.\n",
    "- 첫 번째!! : 추가된 사건 C가 입력(조건)이라면, 출력(결과)로, 출력(결과)였다면 입력(조건)으로 위치시킵니다!! -- P(  `C`  |   )\n",
    "- 두 번째!! : prior에서 출력(결과)에 위치해 있는 사건 중, 하나를 likelihood의 입력(조건)으로 위치시킵니다!! -- P(  C  |  `A`  )\n",
    "- 세 번째!! : 나머지는 본래 위치대로 집어넣습니다!! -- P(`B`,C|A,`D`)(B와 D는 기존에 prior 사건의 각각 출력과 입력 위치에 있던 사건들이고 그 상태대로 그대로 넣어준 것입니다.\n",
    "- 따라서!! : `P(A,B|D)`라는 prior 가 `P(A,B|C,D)`라는 posterior가 되게끔하는 `likelihood`는 `P(B,C|A,D)`가 되었습니다!!! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음에는 확률모형과 확률변수에 대해서 다뤄보겠습니다~!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "감사합니다!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
