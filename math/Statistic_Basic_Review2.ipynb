{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 번째 review에서는 기댓값, 분산(표준 편차)에 대해서 다루도록 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기댓값\n",
    "### 확률 분포의 기댓값\n",
    "- 만약 확률 변수(random variable)이 따르고 있는 확률 모형, 확률 밀도 함수(pdf)를 알고 있을 경우에 `이론적인 평균`을 구할 수 있습니다.\n",
    "- 이 때, 이 이론적인 평균을 확률 변수의 `기댓값(Expectation)`이라고 합니다.\n",
    "- 기댓값을 구하는 방법은:\n",
    "    - In discrete rv: `E[X] = x_i P(x_i) within sample space`\n",
    "- 확률 변수에서 나올 수 있는 값, 표본 공간의 원소 x_i 의 가중 평균입니다. 이때 가중치는 확률 질량 함수 P(x_i)입니다.\n",
    "    - In continous rv: `E[X] = integral of xf(x)ds from -infitie to infinite`\n",
    "- 확률 밀도 함수 f(x)를 가중치로 x를 적분하여 기댓값을 구합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 확률 밀도 함수의 모양과 기댓값\n",
    "- 기댓값은 여러가지 가능한 x의 값들을 `확률 밀도 값`에 따라서 가중합을 한 것이므로 가장 확률 밀도가 `높은` x값 근처의 값이 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 기댓값의 성질\n",
    "- 확률 변수가 아닌 고정된 스칼라 값에 대한 기댓값은:\n",
    "    - E(c) = c\n",
    "- 스칼라 곱에 대한 기댓값은:\n",
    "    - E(2X) = 2E(X)\n",
    "- 위 두 개의 조건에 따라서 기댓값은 `선형성`을 가지게 됩니다.\n",
    "    - E(2X+Y)=2E(X)+E(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기댓값과 샘플 평균\n",
    "- 위에서 다뤘던 기댓값은 확률 변수 X 에 대해 한 번 짚고 넘어가볼까요?!\n",
    "    - 이산확률변수의 기댓값:\n",
    "        - 확률 변수에서 나올 수 있는 확률값과 표본 공간의 원소의 가중 평균\n",
    "    - 연속확률변수의 기댓값:\n",
    "        -  확률 밀도 함수를 가중치로 x라는 표본을 적분한 것\n",
    "- 기댓값과 샘플 평균은 다른 것임을 확실하게 알고 넘어가야 합니다!!\n",
    "    - 기댓값: 확률 변수 X는 확률론적 데이터이고, 이들의 데이터가 가질 경향성, 즉 확률 밀도, 확률 질량이 높은 x 값 근처를 의미합니다.\n",
    "    - 샘플 평균: 확률 변수 X에서 나오는 생성한(확률 변수는 generator입니다.)표본들의 평균을 의미합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 샘플 평균의 확률 분포\n",
    "- 확률 변수 X로 부터 N개의 표본을 만들어 샘플 평균을 구하면, 이 값 또한 예측이 불가능한 확률론적 데이터가 됩니다.\n",
    "- 이해하기 쉽게 설명을 드리면,\n",
    "    - 확률 변수 X(굳이 X가 아니여도 됩니다!) 에서 샘플을 x_1,x_2,...,x_n개를 찍어냅니다. 그 후에 이들을 평균을 내면 1/n np.sum(list of x_i) 샘플 평균이 됩니다. 여기서 x_i라는 샘플들을 찍어낼 때마다 예측불가능한 확률론적 데이터이기 때문에 샘플 평균 또한 확률론적 데이터가 됩니다. 이에 따랏 확률 분포를 생성할 수 있습니다.\n",
    "- 확률 변수 X 에서 나온 표본으로 만들어진 샘플 평균의 확률 변수는 X_bar 로 표기합니다.\n",
    "    - 샘플 평균의 확률 변수?? \n",
    "        - 찍어낼때마다 다른 값이 나올 수 있으므로 이 또한, 확률 변수로 간주할 수 있습니다. 이 전 review에서 말씀드렸다시피, 기존 변수의 기능과는 다르게 찍어낼 때마다 다른 값(data)가 나올 수 있는 확률론적 데이터를 의미하는 것이 확률 변수라고 말씀드렸습니다. domain에 어떠한 샘플을 넣으면 range에 실수값이 나오는 것 그것이 확률 변수입니다. 따라서 어떠한 확률 변수의 샘플들을 넣느냐에 따라 샘플 평균(이것 하나의 값(value)가 됩니다.) 이라는 실수 값이 나오게 되므로 확률 변수입니다. 설명이 충분한가요...???ㅎㅎ\n",
    "- `X_bar = 1/N X_i(from 1 to N)` 이 식이 의미하는 바는 간단하지만, 짚고 넘어가야 할 것은 확률 변수 X 의 샘플 평균에서는 항상 확률 변수 X라는 같은 데이터 생성기를 사용해야 한다느 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기댓값과 샘플 평균의 관계\n",
    "- 샘플 평균의 기댓값은 확률 변수의 기댓값과 같습니다.\n",
    "-`E[X] = E[X_bar]`\n",
    "- 이해가 잘 안가실 수도, 확실하게 와닿지 않으실 수도 있습니다. 직관적으로 생각해보면 그렇게 어렵지 않은데요!\n",
    "    - 샘플 평균이 같은 확률 변수(정확하게 copy한)만든 N개의 데이터들을 더해 1/N을 취한 것입니다.그리고 확률 변수는 단 한 개의 확률 변수 X입니다. 이들의 기댓값? 당연히 같을 수 밖에 없습니다. 여기에 증명을 쓰는 것은 쉽지 않아 생각하겠지만, 확률 변수에서 나온 데이터 N개에 다시 1/N을 곱하게 되면 1입니다. 그러면 E[X] 만 남게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 중앙값과 최빈값\n",
    "- 중앙값은 누적확률분포 F(x)에서 계산할 수 있습니다.\n",
    "    - 중앙값의 의미가 말 그대로 딱 중앙의 값을 의미하기 때문에 이 전에 나올 그리고 이후에 나올 데이터의 확률이 같게끔 해주면 `F(median) = 0.5`가 되게끔 해주면 됩니다!\n",
    "- 최빈값은 그 데이터가 나올 확률이 가장 큰 것을 의미합니다. 다만 주의할 점은 전에 말씀드렸다시피, 연속확률변수에서 어떠한 특정한 값이 나올 확률은 0이기 때문에 여기서는 확률 밀도 함수으ㅢ 값이 가장 큰 확률 변수의 값으로 지정하게 됩니다. 따라서\n",
    "    - mode = argmax_x f(x)가 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 분산과 표준 편차\n",
    "- 확률 변수의 분산 Var[X]는 (확률 변수 - 기댓값)의 제곱을 취한 것의 기댓값입니다.\n",
    "- 이산 확률 변수의 경우:\n",
    "    - `(x_i - sample mean)**2 P(x_i) within sample space`\n",
    "- 연속 확률 변수의 경우:\n",
    "    - `integral of (x-mu)**2 f(x)dx within -infinite to infinite`\n",
    "- 즉 ,`분산은 평균으로부터 데이터까지의 거리 제곱`을 `확률 (P(x) or f(x))로 가중치`를 취해 평균한 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분산의 성질\n",
    "- 분산은 0 또는 양수입니다.\n",
    "- 상수 값 c에 대해서 그 분산 값은 0입니다.\n",
    "- Scalar multiplication에 대해서는 `Var[cX] = c**2Var[X]`입니다.\n",
    "- `Var[x] = E{X**2] - Mu**2`\n",
    "- `Var[X+Y] = V[X] + V[Y] + 2E[(X-M_x)(Y-M_y)]`\n",
    "- 두 확률 변수 X와 Y가 독립이면 `2E[(X-M_x)(Y-M_y)]`이므로 이 때는 덧셈에 대하여 닫혀있습니다. 즉, 두 확률 변수의 합의 분산은 분산의 합과 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 샘플 평균의 분산\n",
    "- 위에서 샘플 평균의 기댓값을 구하였고, 그 값은 확률 변수의 기댓값과 같음을 증명했습니다.\n",
    "- 샘플 평균 X_bar에 대한 분산 Var[X_bar]의 분산은 1/N Var[X]와 같습니다.\n",
    "- `Var[X_bar] = 1/N Var[X]`\n",
    "- 따라서 샘플 평균을 취하는 샘플의 수(N)이 커지면 샘플 평균의 값은 변동(분산)이 적어지게 됩니다. 샘플의 수가 무한대로 다가가면 분산은 0이 되어서 샘플 평균의 값은 항상 일정한 값이 나옵니다.\n",
    "- 이를 이용해서 샘플의 갯수를 충분히 크게 한 후에, 샘플 평균의 기댓값을 구하면 원래 확률 변수의 기댓값의 근사값을 구할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 샘플 분산의 기댓값\n",
    "- 샘플 분산 S^2 의 기댓값을 구하면 이론적인 분산 signma^2와 같아지는 것이 아니라 (N-1)/N 만큼 작아지게 됩니다. \n",
    "- `E[S^2] = (N-1)/N sigma^2`\n",
    "- 이전에 다뤘던 샘플 분산을 구하는 방법에서 비편향성을 부여하기 위해서 1/(N-1)을 취해주었던 것을 기억하시나요?!\n",
    "    - E[S^2_unbiased] = E[`1/(N-1)` (X_i - X_bar)^2 from i to N]\n",
    "- 샘플 분산의 기댓값이 확률 변수의 분산과 같아지기 위해서 보정값(correction)을 취해준 것입니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
